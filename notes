#########
#Editor Config
#########
Set up the baseline decisions about tooling - we need a JavaScript editor
So everyone on our team uses the same critical editor settings, like spaces versus tabs, line endings, and more, by using a standard called editorconfig
1. Create the file with the settings
2. Some editor, like vscode, requires a plugin which have to be installed
(check https://editorconfig.org/)
That's all

#########
#Package Management
#########
Use NPM
create package.json which npm uses
npm install

#########
#Development Webserver
#########
options:
http-server
live-server
Express
budo
webpack dev server
browsersync

Using Express,
Already installed. see the packagejson file
From root directory, Create a folder 'buildScripts', which houses the srcServer.js file (where webserver is set up) serving a file
From root directory, create a folder 'src', in it create the file 'index.html'

#########
#Share Work In Progress
#########
Tools:
localtunnel: easy to share;
npm install localtunnel -g
start the app
lt --port 3000
lt --port 3000 --subdomain ezekiel //or sub domain of ezekiel

ngrok
sign up
install ngrok
install authtoken
start app
./ngrok http 80
//secutiry

now
quick depoly node.js to the cloud, hosting persists

npm install
create start script
now //no need to keep your files

surge
Quickly host static files
npm install
surge

#########
#Set Up Automation
#########
options
Grunt, Gulp, npm scripts

Declared in packagejson
leverage ur OS' command line
Directly use npm package
Call separate node scripts
convention-based pre/post hooks
leverage worlds largest package manager
why npm scripts?
Use tools Directly
No need for separate plugins
Simpler debudding
Better bugs
Esay to learn


decalred the scripts in packagejson
"start": "node buildScripts/srcServer.js"
"prestart": "node buildScripts/startMessage.js", //prestart will run before start, poststart will run after start
"localtunnel": "lt --port 3000" //npm run localtunnel
"share": "npm-run-all --parallel start localtunnel" //run 'start' and 'localtunnel' in parallel
"share": "npm-run-all --parallel start localtunnel -s" //run 'start' and 'localtunnel' in parallel, '-s' removes extraneous info

packages called from npm scripts do need to be installed globally


#########
# Transpiling
#########
Babel
Transpile the lastest innovations
Write standardized js
leveage full ES ecosystem
use experimental features earlier
ES6 imports are statically analyzable

Typescripts
Enhanced autocomplete
enhanced readerbility
safer refactory
additional non-standrd features

Babel
create a new file in root called .babelrc
basically this:
{
    "presets": [
        "latest"
    ]
}

In packagejson file: "prestart": "babel-node buildScripts/startMessage.js"; see the babel-node
so ES6 syntax in the startMessage script is transpilled

#########
# Bundling
#########
webpack

in root set up, webpack.config.dev.js

import webpack from 'webpack';
import path from 'path';

export default {
  debug: true, //want to see bugs and treat them
  devtool: 'inline-source-map',
  noInfo: false, // see files that are being bundled
  entry: [
    path.resolve(__dirname, 'src/index') //entry point for webpack
  ],
  target: 'web', //could target electron, or apps
  output: {
    path: path.resolve(__dirname, 'src'), //source of the producted virtual file generated by webpack
    publicPath: '/',
    filename: 'bundle.js' //name of the file
  },
  devServer: {
      contentBase: path.resolve(__dirname,'src')
  },
  plugins: [],
  module: {
    loaders: [
      {test: /\.js$/, exclude: /node_modules/, loaders: ['babel']},
      {test: /\.css$/, loaders: ['style','css']}
    ]
  }
};

index.js is created in src
the script tag is added to the index.html file
the server is configure to use webpack
**.babelrc is moved to root

to generate source map, we add 'debugger' to where we would like to debug

#########
#8 Linting
#########
Enforce consistency:
curly braces position
confirm/ alert
Trailing commas
Globals
eval

Avoid mistakes:
Extra parathesis
overwriting function
assignment in conditionals
missing default case in switch
debugger/ console.log

JsLint, JsHint, EsHint

Config. Location: Separate file, or packagejson
Rules to enable?
Warnings (can continue development) or errors(breaks the build)? use both?
Which plugins?
Use a preset? From scratch or the Recommended (w can tweaked based on feedback)

EsLInt does not watch files. solution? esint-loader or eslint-watch?
EsLint doesnt use experiemental features; to use, try babel-esint, remeber to use the necessary plugin


One place to check
Univerversal config
part of contnous integration

Set up EsLint
Eslint recommendation
Eslint watch

create .eslintrc.json
{
  "root": true, //declare as root
  "extends": [
    "eslint:recommended", //use the recommeded rule
    "plugin:import/errors", //lintin for imports
    "plugin:import/warnings"
  ],
  "parserOptions": {
    "ecmaVersion": 7,
    "sourceType": "module" //standard
  },
  "env": {
    "browser": true, //for global variables
    "node": true,
    "mocha": true
  },
  "rules": {
      "no-console": 1 //rules to overwrite; 1 warning, 2 error, 0 means off
  }
}

set to run with npm script...
it can run on its won, but we want to use it with eslint-watch, --color flag colors the warnings/errors
lint all webpack.config files (dev and pro) in src and buildScripts
"lint": "esw webpack.config.* src buildScripts --color"

npm run lint -s //run the script; -s flag removes nodejs npm ERR; remember to cd using the right case for the directory

in src sever, you dont care in build files, to disable: /*eslint-disable no-console */ at the top of the file

aliter:
at the end of a line // eslint-disable-line no-console

"lint:watch": "npm run lint -- --watch"// this says run the lint script, pass the --watch tag as well
use in start, so that it starts at starup


#########
#9 Testing
#########
Unit style - single function or module
integration style - interactions between modules
UI style - Automate interactions with UI

Testing decisions
Framework? Mocha, Jasmine, Tape, QUnit, AVA, Jest - MOCHA
Assertion Library? Some framework comes with one, but not Mocha: CHI
Helper Library? JSDOM (simulate the browser's DOM), Cheerio (JQuery for the server)
Where to run tests? Browser (Karma, Testem),Headless Browser(PhantomJS), In-memory DOM(JSDOM)
Where to put test? Centraized, Alongsize
When to test? Unit Test(ctrl + s),

in buildscript: create testSetup.js
//This file isn't transpiled, so must use commonjs and es5

//Register babel to tanspile before our test run.
require('babel-register')();

//Disable webpack features that Mocha dosent understand
require.extensions['.css'] = function() {};

in packagejson
"test": "mocha --reporter progress buildScripts/testSetup.js \"src/**/*.test.js\""

npm run test should fail: No test

now create the test file: in src:
index.test.js
import {expect} from 'chai';

describe ('Our first test',() => {
    it('should pass',() => {
        expect(true).to.equal(true); //false or true to see fail and pass
    });
});

more test:
describe('index.html',() => {
    it('should say hello',(done) => { //when running a asynchronous stuffs, use done
        const index = fs.readFileSync('./src/index.html', 'utf-8');
        jsdom.env(index,function(err, window){
            const h1 = window.document.getElementsByTagName('h1')[0];
            expect(h1.innerHTML).to.equal('Hello World!');
            done();
            wondow.close()
        });
    });
});

TEST watch
In packagejson;
"test:watch": "npm run test -- --watch"

Continuous integration server: CI Server
Travis - Linux
Appveyor - Windows

Does the code work on other machine?
Forgot to commit new file
forgot to update packagejson
commit dosent run crosssplatform
node version conflict
bad merge
didnt run tests

CI Server builds once you make a commit: Run aumated build
Run Your test on multiple machine
Check code coverage
automate deployment

see the appveyor and travis files in the root directory



#########
#10 HttpCalls
#########
HTTP Call Approaches
Node - http, request
Browser - XMLHttpRequest, jquery, Fetch
Node and Browser - isomorphic-fetch, xhr, SuperAgent, Axios

Why centralize:
Configure alll calls
Handle preloader logic
Handle errors
Single seam for mocking

Mock:
Use express to serve the api:
add a new router:
app.get('/users', fuction (req, res){
  res.json([
    {"id": 1, "firstName": "Matthew", "lastName" = "oye", "email": "ml@gmail.com"},
    {"id": 2, "firstName": "Cornel", "lastName" = "okon", "email": "co@gmail.com"},
    {"id": 3, "firstName": "Osita", "lastName" = "Irene", "email": "oi@gmail.com"},
  ]);
}); //just hot coding now // test the router

Next:
Update the browser tocall the api using fetch

in src folder, api folder, create the userApi.js
import "whatwg-fetch";

export function getUsers (){
  return get('users');
}

function get(url){
  return fetch(url).then(onSuccess, onError);
}

function onSuccess(response){
  return response.json();
};

function onError(error){
  console.log(error); //eslint-disable-line no-console
};

//let's call it the browser, head to the index.html
<table>
  <thead>
    <th>&nbsp</th>
    <th>id</th>
    <th>First Name</th>
    <th>Last Name</th>
    <th>Email</th>
  </thead>
  <tbody id ='users'>

  </tbody>

</table>

//head to index.js to populate the table with api calls
import {getUsers} from "./api/userApi";

//Populate table of users via API calls.
getUsers().then (result => {

    let userBody = "";

    result.foEach(user =>{
        userBody =
        `
        <tr>
            <td> <a href="#" data-id="${user.id}" class="deleteUser">Delete</a></td>
            <td>${user.id}</td>
            <td>${user.firstName}</td>
            <td>${user.lastName}</td>
            <td>${user.email}</td>
        </tr>
        `
  });

  global.document.getElementsById('users').innerHTML = usersBody

  }); //remeber to change test, to test that h1 returns Users

  why polifils
  use polyfill.io //this website gives a script that checks if the browser supports fetch. it povides polyfills if it does not


Why mock http?
Unit testing
instant response
keep working when service are down
rapid prototyping
avoid inter team bottle neck
work offline

How to MOck Http?
Nock
Static json //same data everytime, dont store change
Create Development webserver
-api-mock
- JSON server
- JSON SChema faker
- Browsersyn
- Express, etc


Steps:
Declare our schema - JSON Schema faker: json-schema.org
Generate Random Data
-faker.js, chance.js, randomexp.js
Serve Data via API
- JSON Server

in build script folder, create a file: mockDataSchema.js
bit.ly/ps-mock-data-schema
export const schema = {
  "type": "object",
  "properties": {
    "users": {
      "type": "array",
      "minItems": 3,
      "maxItems": 5,
      "items": {
        "type": "object",
        "properties": {
          "id": {
            "type": "number",
            "unique": true,
            "minimum": 1
          },
          "firstName": {
            "type": "string",
            "faker": "name.firstName"
          },
          "lastName": {
            "type": "string",
            "faker": "name.lastName"
          },
          "email": {
            "type": "string",
            "faker": "internet.email"
          }
        },
        "required": ["id", "firstName", "lastName", "email"]
      }
    }
  },
  "required": ["users"]
};

file in build script: generateMockData.js
/*eslint-disable no-console */
import jsf from 'json-schema-faker';
import {schema} from './mockDataSchema';
import fs from "fs";
import chalk from 'chalk';

const json = JSON.stringify (jsf(schema))

fs.writeFile("./src/api/db.json", json, function (err){
  if (err){
    return console.log(chalk.red(err));
  } else {
    console.log(chalk.green("Mock Data Generated"));
  }
});


"start-mockapi": "json-server --watch src/api/db.json --port 3001" //try out on cmd

randomise data every time we start the app
"prestart-mockapi": "npm run generate-mock-data"

then add start-mockapi on the start script

create a file in api, baseUrls.js
export default functio getBaseUrl (){
  const inDevelopment = window.location.hostname === 'localhost';
  return inDevelopment ? 'http://localhost:3001/' : '/';
}

in userApi file
import "whatwg-fetch";
import getBaseUrl from './baseUrl';

const baseUrl = getBaseUrl ();

export function getUsers (){
  return get('users');
}

function get(url){
    return fetch(baseUrl + url).then(onSuccess, onError);
}

function onSuccess(response){
  return response.json();
}

function onError(error){
  console.log(error); //eslint-disable-line no-console
}

//Handling data manipulation
//in userApi.js
add:
export function deleteUser(id){
  return del(`users/${id}`);
}

add:
function del (url) {
  const request = new Request(baseUrl + url, {
    method: "DELETE"
  });
  return fetch(request).then(onSuccess, onError);
}

Handle in index.js:
   const deleteLinks = global.document.getElementsByClassName ('deleteUser');

    //must use array.from to create a real array from a DOM collection
    //getElementsByClassname only returns an 'array like' object
    Array.from (deleteLinks, link => {
        link.onclick = function (event){
            const element = event.target;
            event.preventDefault();
            deleteUser (element.attributes["data-id"].value);
            const row = element.parentNode.parentNode;
            row.parentNode.removeChild(row);
        };
    });
});

//remember to import deleteUser

#########
#11 Project Development
#########

Examples of:
-Directory structure and file naming
-Framework usgae
-Testing
-Mock API
-Automated deployment
Codifies Descisions
Interactive example of working with starter

JS file lives in the .js files
Dont put it in html file in a script tag <script></script>
How would you test it? lint it? transpile it? reuse it, import explicit depencies

Avoid dynamically generating Javascript logic. Dynamically gnerate JSON instead

Organise by features, not file types

POJOs, plain old javascript objects that are not framework specific wherever possible.
easily testable

#########
#12 Production bUILD
#########
Minification: Speed page loads, reduce bandwidth:
shortens variable and function names
removes comments
removes whitespace and new lines
dead code elimination / tree shaking
Debug via sourcemap

St Up Minification
Make a copy:
import webpack from "webpack";

devtool: 'source-map', //see code even if its been minified and bundled
path: path.resolve(__dirname, 'dist')

in plugin:
//Eliminate duplicate packages when generating bundle
new webpack.optimize.DedupePlugun(),
//Minify JS
new webpack.optimize.UglifyPlugin()

a script that will run our webpack config prod build
in build scripts, create build.js
/*eslint-disable no-console */
import webpack from 'webpack';
import webpackConfig from '../webpack.config.prod';
import chalk from 'chalk';

process.env.NODE_ENV = 'production' //declaring that we are running node, Babel uses this

webpack(webpackConfig).run(err, stats) => {
  if (err) {//so a fatal error occrued here.
    console.log(chalk.red(err));
    return 1;
  }
  const jsonStats = stats.toJson();

  if (jsonStats.hasErrors) {
    return jsonStats.errors.map(error => console.log(chalk.red(error)));
  }

  if (jsonStats.hasWarnings) {
    console.log(chalk.yellow('Webpack generated the following warnings: '));
    jsonStats.warnings.map(warning => console.log(chalk.yelllow(warning)));
  }

  console.log(`Webpack stats: ${stats}`);

  //if we get this far, the build succeeded.
  console.log(chalk.green('Your app has been built for production and written to /dist!'))

  return 0;
}


//to run the final production of the app on the local machine to make sure evrything looks good
//file called distServer in build scripts

//not for use in real production

copy source server to distServer

and edit
